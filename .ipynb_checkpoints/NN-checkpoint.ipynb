{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv').drop([379, 24598], axis=0)\n",
    "test_data = pd.read_csv('./data/test_x.csv')\n",
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "             'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "             'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "             'index', 'hand']\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['voted']\n",
    "train_y = 2 - train_y.to_numpy()\n",
    "\n",
    "train_x = train_data.drop(drop_list + ['voted'], axis=1)\n",
    "train_x = train_x.astype(replace_dict)\n",
    "train_x = pd.get_dummies(train_x)\n",
    "train_x = train_x.to_numpy()\n",
    "\n",
    "test_x = test_data.drop(drop_list, axis=1)\n",
    "test_x = test_x.astype(replace_dict)\n",
    "test_x = pd.get_dummies(test_x)\n",
    "test_x = test_x.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[:, :20] = (train_x[:, :20] - 3.) / 2.\n",
    "test_x[:, :20] = (test_x[:, :20] - 3.) / 2\n",
    "train_x[:, 20] = (train_x[:, 20] - 5.) / 5.\n",
    "test_x[:, 20] = (test_x[:, 20] - 5.) / 5.\n",
    "train_x[:, 21:31] = (train_x[:, 21:31] - 3.5) / 3.5\n",
    "test_x[:, 21:31] = (test_x[:, 21:31] - 3.5) / 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.5,  1. , ...,  1. ,  0. ,  0. ],\n",
       "       [ 1. ,  1. ,  0. , ...,  0. ,  0. ,  1. ],\n",
       "       [ 0.5, -1. , -1. , ...,  0. ,  1. ,  0. ],\n",
       "       ...,\n",
       "       [ 0.5, -1. , -1. , ...,  0. ,  1. ,  0. ],\n",
       "       [-1. ,  0. ,  0.5, ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. ,  1. , ...,  0. ,  1. ,  0. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82109\\anaconda3\\envs\\pytorch_python3.7\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\82109\\anaconda3\\envs\\pytorch_python3.7\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "C:\\Users\\82109\\anaconda3\\envs\\pytorch_python3.7\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "01/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [01:58<00:00,  1.12s/it]\n",
      "02/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [01:55<00:00,  1.10s/it]\n",
      "03/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [01:59<00:00,  1.13s/it]\n",
      "04/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:13<00:00,  1.27s/it]\n",
      "05/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [03:20<00:00,  1.91s/it]\n",
      "06/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:16<00:00,  1.30s/it]\n",
      "07/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:20<00:00,  1.33s/it]\n",
      "08/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:21<00:00,  1.35s/it]\n",
      "09/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:22<00:00,  1.36s/it]\n",
      "10/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:22<00:00,  1.36s/it]\n",
      "11/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:22<00:00,  1.35s/it]\n",
      "12/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:22<00:00,  1.36s/it]\n",
      "13/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:15<00:00,  1.29s/it]\n",
      "14/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:19<00:00,  1.33s/it]\n",
      "15/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:21<00:00,  1.35s/it]\n",
      "16/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:22<00:00,  1.35s/it]\n",
      "17/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:21<00:00,  1.35s/it]\n",
      "18/18: 100%|█████████████████████████████████████████████████████████████████████████| 105/105 [02:17<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "train_y = torch.tensor(train_y, dtype=torch.float32, device=DEVICE)\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32, device=DEVICE)\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32, device=DEVICE)\n",
    "train_len, test_len = len(train_x), len(test_x)\n",
    "\n",
    "N_MODEL = 18\n",
    "N_EPOCH = 105\n",
    "BATCH_SIZE = 128\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False\n",
    "}\n",
    "prediction = np.zeros((11383, 1), dtype=np.float32)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    for no in range(N_MODEL):\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(train_x, train_y),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "        test_loader = DataLoader(TensorDataset(test_x, torch.zeros((test_len,), dtype=torch.float32, device=DEVICE)),\n",
    "                                 shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        model = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(91, 96, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(96, 36, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(36, 1)\n",
    "        ).to(DEVICE)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=4e-2)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=N_EPOCH // 4, eta_min=1.2e-5)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(no + 1, N_MODEL)):\n",
    "            for idx, (xx, yy) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                pred = model(xx).squeeze()\n",
    "                loss = criterion(pred, yy)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(epoch + idx / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (xx, _) in enumerate(test_loader):\n",
    "                xx = xx.to(DEVICE)\n",
    "                pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "                prediction[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] += pred[:, :] / N_MODEL\n",
    "\n",
    "df = pd.read_csv('./data/sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction\n",
    "df.to_csv('./result/{}.csv'.format(datetime.now().strftime('%m%d-%H%M')), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping tutorial\n",
    "\n",
    "https://www.kaggle.com/akhileshrai/tutorial-early-stopping-vanilla-rnn-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화하기\n",
    "(정규화하고자 하는 값 - 데이터 값들 중 최소값) / (데이터 값들 중 최대값 - 데이터 값들 중 최소값)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
