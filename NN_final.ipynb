{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test_x.csv')\n",
    "\n",
    "# drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "#              'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "#              'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "#              'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "#              'index']\n",
    "\n",
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "             'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "             'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "             'index', 'hand']\n",
    "\n",
    "# drop_list = ['index']\n",
    "\n",
    "train_data = train_data.drop(train_data[train_data.familysize >= 20].index)\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설문 소요시간 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_time = []\n",
    "# for col in list(train_data.columns):\n",
    "#     if re.match('Q[a-z]E', col):\n",
    "#         survey_time.append(col)\n",
    "# train_data[survey_time] = train_data[survey_time].apply(lambda x: x / (x.max()*10), axis=1)   \n",
    "\n",
    "# survey_time = []\n",
    "# for col in list(test_data.columns):\n",
    "#     if re.match('Q[a-z]E', col):\n",
    "#         survey_time.append(col)\n",
    "# test_data[survey_time] = test_data[survey_time].apply(lambda x: x / (x.max()*10), axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['voted']\n",
    "train_y = 2 - train_y.to_numpy()\n",
    "\n",
    "train_x = train_data.drop(drop_list + ['voted'], axis=1)\n",
    "train_x = train_x.astype(replace_dict)\n",
    "train_x = pd.get_dummies(train_x)\n",
    "\n",
    "test_x = test_data.drop(drop_list, axis=1)\n",
    "test_x = test_x.astype(replace_dict)\n",
    "test_x = pd.get_dummies(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# index 확인하기\n",
    "# for i, d in enumerate(train_x.columns):\n",
    "#     print(i, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 설문 소요시간 포함시...\n",
    "\n",
    "# train_x[:, :40] = (train_x[:, :40] - 1.) / 4.\n",
    "# test_x[:, 40] = (test_x[:, 40] - 1.) / 4.\n",
    "\n",
    "# train_x[:, 41] = (train_x[:, 41]) / 3\n",
    "# test_x[:, 41] = (test_x[:, 41]) / 3\n",
    "\n",
    "# train_x[:, 42:52] = (train_x[:, 42:52] - 3.5) / 3.5\n",
    "# test_x[:, 42:52] = (test_x[:, 42:52] - 3.5) / 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 설문 소요시간 미포함시...\n",
    "\n",
    "# train_x[:, :20] = (train_x[:, :20] - 1.) / 4.\n",
    "# test_x[:, 20] = (test_x[:, 20] - 1.) / 4.\n",
    "\n",
    "# train_x[:, 21] = (train_x[:, 21]) / 3\n",
    "# test_x[:, 21] = (test_x[:, 21]) / 3\n",
    "\n",
    "# train_x[:, 22:32] = (train_x[:, 22:32] - 3.5) / 3.5\n",
    "# test_x[:, 22:32] = (test_x[:, 22:32] - 3.5) / 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 설문 소요시간 미포함시... 정규화 다르게..\n",
    "\n",
    "train_x[:, :20] = (train_x[:, :20] - 3.) / 2.\n",
    "train_x[:, 20] = (train_x[:, 20] - 5.) / 5.\n",
    "test_x[:, :20] = (test_x[:, :20] - 3.) / 2\n",
    "test_x[:, 20] = (test_x[:, 20] - 5.) / 5.\n",
    "\n",
    "# train_x[:, 21] = (train_x[:, 21]) / 3\n",
    "# test_x[:, 21] = (test_x[:, 21]) / 3\n",
    "\n",
    "train_x[:, 21:31] = (train_x[:, 21:31] - 3.5) / 3.5\n",
    "test_x[:, 21:31] = (test_x[:, 21:31] - 3.5) / 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x).float()\n",
    "train_y = torch.from_numpy(train_y).float()\n",
    "\n",
    "real_train_x = train_x\n",
    "real_train_y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31863, 13657)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = [.7, .3]\n",
    "\n",
    "train_cnt = int(train_x.size(0) * ratios[0])\n",
    "valid_cnt = train_x.size(0) - train_cnt\n",
    "cnts = [train_cnt, valid_cnt]\n",
    "train_cnt, valid_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31863, 91]) torch.Size([31863])\n",
      "torch.Size([13657, 91]) torch.Size([13657])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(train_x.size(0))\n",
    "\n",
    "train_x = torch.index_select(train_x, dim=0, index=indices)\n",
    "train_y = torch.index_select(train_y, dim=0, index=indices)\n",
    "\n",
    "train_x = train_x.split(cnts, dim=0)\n",
    "train_y = train_y.split(cnts, dim=0)\n",
    "\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "for x_i, y_i in zip(train_x, train_y):\n",
    "    print(x_i.size(), y_i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45520, 91])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "lowest_loss = np.inf\n",
    "best_model = None\n",
    "lowest_epoch = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len, test_len = len(train_x), len(test_x)\n",
    "early_stop = 30\n",
    "print_interval = 5\n",
    "N_MODEL = 15\n",
    "N_EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False\n",
    "}\n",
    "prediction_valid = np.zeros((13660, 1), dtype=np.float32)\n",
    "prediction_test = np.zeros((11383, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train - valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with torch.cuda.device(0):\n",
    "#     for no in range(N_MODEL):\n",
    "\n",
    "#         train_loader = DataLoader(TensorDataset(train_x[0], train_y[0]),\n",
    "#                                   shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "#         valid_loader = DataLoader(TensorDataset(train_x[1], train_y[1]),\n",
    "#                                   shuffle=False, drop_last=True, **LOADER_PARAM)\n",
    "        \n",
    "#         model = nn.Sequential(\n",
    "#             nn.Dropout(0.05),\n",
    "#             nn.Linear(91, 96, bias=False),\n",
    "#             nn.LeakyReLU(0.05, inplace=True),\n",
    "            \n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(96, 36, bias=False),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.Linear(36, 1)\n",
    "#         ).to(DEVICE)\n",
    "#         criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "#         optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=4e-2)\n",
    "#         scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "#             optimizer, T_0=N_EPOCH // 4, eta_min=1.2e-5)\n",
    "\n",
    "#         for epoch in range(N_EPOCH):\n",
    "#             train_loss, valid_loss = 0, 0\n",
    "#             y_hat = []\n",
    "        \n",
    "#             model.train()\n",
    "#             for idx, (xx, yy) in enumerate(real_train_loader):\n",
    "#                 optimizer.zero_grad()\n",
    "#                 print(xx.size())\n",
    "#                 xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "#                 pred = model(xx).squeeze()\n",
    "#                 loss = criterion(pred, yy)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 scheduler.step(epoch + idx / len(real_train_loader))\n",
    "#                 train_loss += float(loss)\n",
    "                \n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 valid_loss = 0\n",
    "#                 for idx, (xx, yy) in enumerate(valid_loader):\n",
    "#                     xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "#                     pred = model(xx).squeeze()\n",
    "#                     loss = criterion(pred, yy)\n",
    "\n",
    "#                     valid_loss += float(loss)\n",
    "#                     y_hat += [pred]\n",
    "\n",
    "#             valid_loss = valid_loss / len(valid_loader)\n",
    "\n",
    "#             if (epoch + 1) % print_interval == 0:\n",
    "#                 print('Epoch %d: train loss=%.4e  valid_loss=%.4e  lowest_loss=%.4e' % (\n",
    "#                     epoch + 1,\n",
    "#                     train_loss,\n",
    "#                     valid_loss,\n",
    "#                     lowest_loss,\n",
    "#                 ))\n",
    "\n",
    "#             if valid_loss <= lowest_loss:\n",
    "#                 lowest_loss = valid_loss\n",
    "#                 lowest_epoch = epoch\n",
    "\n",
    "#                 best_model = deepcopy(model.state_dict())\n",
    "#             else:\n",
    "#                 if early_stop > 0 and lowest_epoch + early_stop < epoch + 1:\n",
    "#                     print(\"There is no improvement during last %d epochs.\" % early_stop)\n",
    "#                     break\n",
    "\n",
    "#         print(\"The best validation loss from epoch %d: %.4e\" % (lowest_epoch + 1, lowest_loss))\n",
    "#         model.load_state_dict(best_model)\n",
    "\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for idx, (xx, _) in enumerate(valid_loader):\n",
    "#                 xx = xx.to(DEVICE)\n",
    "#                 pred = (torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "#                 prediction_valid[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction_valid)), :] += pred[:, :] / N_MODEL\n",
    "\n",
    "\n",
    "# roc_auc_score(train_y[1], prediction_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valid auc score\n",
    "1. 0.7664986978004593\n",
    "2. 0.7675935061471474  (설문조사답변 정규화 다르게..)\n",
    "3. 0.7710123794060724  ~ 0.7738559380625569 (hand변수 포함 + 정규화)\n",
    "4. 0.7657323921703704  (familysize 정규화) --> 제외!!\n",
    "5. 0.7611448774735629 ~ 0.7618059057348474 (설문시간 포함+ 정규화)\n",
    "6. 0.77171753378888 ~ 0.7727322346127534 (설문시간 포함+ 정규화 + layer늘림)\n",
    "7. 0.7677365629016805 ~ 0.7741115155537603 (설문시간 포함+ 정규화 + layer더 늘림)\n",
    "8. 0.7635808020457102 ~ 0.776610620093519 (설문시간 포함+ 정규화 + layer더 늘림 + batchnorm)\n",
    "9. 0.7643981540072351 ~ 0.7708937758928313 (설문시간 포함+ 정규화 + layer더 늘림 + batchnorm + 설문마키아벨리) --> 제외!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16it/s]\n",
      "02/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16it/s]\n",
      "03/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17it/s]\n",
      "04/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:27<00:00,  1.14it/s]\n",
      "05/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16it/s]\n",
      "06/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:28<00:00,  1.13it/s]\n",
      "07/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17it/s]\n",
      "08/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [02:06<00:00,  1.26s/it]\n",
      "09/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [02:47<00:00,  1.68s/it]\n",
      "10/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17it/s]\n",
      "11/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:24<00:00,  1.18it/s]\n",
      "12/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19it/s]\n",
      "13/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17it/s]\n",
      "14/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16it/s]\n",
      "15/15: 100%|█████████████████████████████████████████████████████████████████████████| 100/100 [01:26<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    for no in range(N_MODEL):\n",
    "\n",
    "        real_train_loader = DataLoader(TensorDataset(real_train_x, real_train_y),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "    \n",
    "        test_loader = DataLoader(TensorDataset(test_x, torch.zeros((test_len,), dtype=torch.float32, device=DEVICE)),\n",
    "                                 shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        model = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(91, 96, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(96, 36, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(36, 1)\n",
    "        ).to(DEVICE)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=4e-2)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=N_EPOCH // 4, eta_min=1.2e-5)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(no + 1, N_MODEL)):\n",
    "            for idx, (xx, yy) in enumerate(real_train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                pred = model(xx).squeeze()\n",
    "                loss = criterion(pred, yy)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(epoch + idx / len(real_train_loader))\n",
    "                \n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (xx, _) in enumerate(test_loader):\n",
    "                xx = xx.to(DEVICE)\n",
    "                pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "                prediction_test[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction_test)), :] += pred[:, :] / N_MODEL\n",
    "\n",
    "df = pd.read_csv('./data/sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction_test\n",
    "df.to_csv('./result/{}.csv'.format(datetime.now().strftime('%m%d-%H%M')), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
