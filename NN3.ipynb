{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv').drop([379, 24598], axis=0)\n",
    "test_data = pd.read_csv('./data/test_x.csv')\n",
    "# drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "#              'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "#              'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "#              'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "#              'index', 'hand']\n",
    "drop_list = ['index']\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설문조사 소요시간을 사람별로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_time = []\n",
    "for col in list(train_data.columns):\n",
    "    if re.match('Q[a-z]E', col):\n",
    "        survey_time.append(col)\n",
    "train_data[survey_time] = train_data[survey_time].apply(lambda x: x / (x.max()*10), axis=1)   \n",
    "\n",
    "survey_time = []\n",
    "for col in list(test_data.columns):\n",
    "    if re.match('Q[a-z]E', col):\n",
    "        survey_time.append(col)\n",
    "test_data[survey_time] = test_data[survey_time].apply(lambda x: x / (x.max()*10), axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.086874</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.063221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064933</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.078240</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.068584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.048103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.049074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.029434</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  QaA       QaE  QbA       QbE  QcA       QcE  QdA       QdE  QeA  \\\n",
       "0      0  3.0  0.023018  4.0  0.086874  5.0  0.063221  1.0  0.064933  2.0   \n",
       "1      1  5.0  0.014946  5.0  0.030330  3.0  0.078240  5.0  0.068584  1.0   \n",
       "2      2  4.0  0.048103  1.0  0.043865  1.0  0.030261  4.0  0.100000  5.0   \n",
       "3      3  3.0  0.002112  3.0  0.009682  4.0  0.004156  3.0  0.013596  1.0   \n",
       "4      4  1.0  0.049074  1.0  0.037427  5.0  0.029434  2.0  0.056220  1.0   \n",
       "\n",
       "   ...  wr_04  wr_05  wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "0  ...      0      1      0      1      1      0      1      0      1      1  \n",
       "1  ...      1      1      0      1      1      0      1      0      1      1  \n",
       "2  ...      1      1      0      1      1      1      1      0      1      1  \n",
       "3  ...      0      0      0      0      1      0      1      0      1      1  \n",
       "4  ...      1      1      1      1      1      0      1      1      1      1  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answers = ['QaA', 'QbA', 'QcA', 'QdA', 'QeA',\n",
    "             'QfA', 'QgA', 'QhA', 'QiA', 'QjA', \n",
    "             'QkA', 'QlA', 'QmA', 'QnA', 'QoA', \n",
    "             'QpA', 'QqA', 'QrA', 'QsA', 'QtA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipping_columns = [\"QeA\", \"QfA\", \"QkA\", \"QqA\", \"QrA\", \"QaA\", \"QdA\", \"QgA\", \"QiA\", \"QnA\"]\n",
    "for flip in flipping_columns: \n",
    "    train_data[flip] = 6 - train_data[flip]\n",
    "    test_data[flip] = 6 - test_data[flip]\n",
    "train_data['Mach_score'] = train_data[Answers].mean(axis = 1) / 5\n",
    "test_data['Mach_score'] = test_data[Answers].mean(axis = 1) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Mach_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "      <th>Mach_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.086874</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.063221</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.064933</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.078240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068584</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.048103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.049074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.029434</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  QaA       QaE  QbA       QbE  QcA       QcE  QdA       QdE  QeA  \\\n",
       "0      0  3.0  0.023018  4.0  0.086874  5.0  0.063221  5.0  0.064933  4.0   \n",
       "1      1  1.0  0.014946  5.0  0.030330  3.0  0.078240  1.0  0.068584  5.0   \n",
       "2      2  2.0  0.048103  1.0  0.043865  1.0  0.030261  2.0  0.100000  1.0   \n",
       "3      3  3.0  0.002112  3.0  0.009682  4.0  0.004156  3.0  0.013596  5.0   \n",
       "4      4  5.0  0.049074  1.0  0.037427  5.0  0.029434  4.0  0.056220  5.0   \n",
       "\n",
       "   ...  wr_05  wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \\\n",
       "0  ...      1      0      1      1      0      1      0      1      1   \n",
       "1  ...      1      0      1      1      0      1      0      1      1   \n",
       "2  ...      1      0      1      1      1      1      0      1      1   \n",
       "3  ...      0      0      0      1      0      1      0      1      1   \n",
       "4  ...      1      1      1      1      0      1      1      1      1   \n",
       "\n",
       "   Mach_score  \n",
       "0        0.59  \n",
       "1        0.52  \n",
       "2        0.38  \n",
       "3        0.67  \n",
       "4        0.60  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설문 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (정규화하고자 하는 값 - 데이터 값들 중 최소값) / (데이터 값들 중 최대값 - 데이터 값들 중 최소값)\n",
    "for col in list(train_data.columns):\n",
    "    if re.match('Q[a-z]A', col):\n",
    "        train_data[col] = (train_data[col] - 1.) / 4.\n",
    "        test_data[col] = (test_data[col] - 1.) / 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['voted']\n",
    "train_y = 2 - train_y.to_numpy()\n",
    "\n",
    "train_x = train_data.drop(drop_list + ['voted'], axis=1)\n",
    "train_x = train_x.astype(replace_dict)\n",
    "train_x = pd.get_dummies(train_x)\n",
    "\n",
    "test_x = test_data.drop(drop_list, axis=1)\n",
    "test_x = test_x.astype(replace_dict)\n",
    "test_x = pd.get_dummies(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['familysize'] = train_x['familysize'].apply(lambda x : 1 if x > 20 else x/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 QaA\n",
      "1 QaE\n",
      "2 QbA\n",
      "3 QbE\n",
      "4 QcA\n",
      "5 QcE\n",
      "6 QdA\n",
      "7 QdE\n",
      "8 QeA\n",
      "9 QeE\n",
      "10 QfA\n",
      "11 QfE\n",
      "12 QgA\n",
      "13 QgE\n",
      "14 QhA\n",
      "15 QhE\n",
      "16 QiA\n",
      "17 QiE\n",
      "18 QjA\n",
      "19 QjE\n",
      "20 QkA\n",
      "21 QkE\n",
      "22 QlA\n",
      "23 QlE\n",
      "24 QmA\n",
      "25 QmE\n",
      "26 QnA\n",
      "27 QnE\n",
      "28 QoA\n",
      "29 QoE\n",
      "30 QpA\n",
      "31 QpE\n",
      "32 QqA\n",
      "33 QqE\n",
      "34 QrA\n",
      "35 QrE\n",
      "36 QsA\n",
      "37 QsE\n",
      "38 QtA\n",
      "39 QtE\n",
      "40 familysize\n",
      "41 hand\n",
      "42 tp01\n",
      "43 tp02\n",
      "44 tp03\n",
      "45 tp04\n",
      "46 tp05\n",
      "47 tp06\n",
      "48 tp07\n",
      "49 tp08\n",
      "50 tp09\n",
      "51 tp10\n",
      "52 wf_01\n",
      "53 wf_02\n",
      "54 wf_03\n",
      "55 wr_01\n",
      "56 wr_02\n",
      "57 wr_03\n",
      "58 wr_04\n",
      "59 wr_05\n",
      "60 wr_06\n",
      "61 wr_07\n",
      "62 wr_08\n",
      "63 wr_09\n",
      "64 wr_10\n",
      "65 wr_11\n",
      "66 wr_12\n",
      "67 wr_13\n",
      "68 Mach_score\n",
      "69 age_group_+70s\n",
      "70 age_group_10s\n",
      "71 age_group_20s\n",
      "72 age_group_30s\n",
      "73 age_group_40s\n",
      "74 age_group_50s\n",
      "75 age_group_60s\n",
      "76 education_0\n",
      "77 education_1\n",
      "78 education_2\n",
      "79 education_3\n",
      "80 education_4\n",
      "81 engnat_0\n",
      "82 engnat_1\n",
      "83 engnat_2\n",
      "84 gender_Female\n",
      "85 gender_Male\n",
      "86 married_0\n",
      "87 married_1\n",
      "88 married_2\n",
      "89 married_3\n",
      "90 race_Arab\n",
      "91 race_Asian\n",
      "92 race_Black\n",
      "93 race_Indigenous Australian\n",
      "94 race_Native American\n",
      "95 race_Other\n",
      "96 race_White\n",
      "97 religion_Agnostic\n",
      "98 religion_Atheist\n",
      "99 religion_Buddhist\n",
      "100 religion_Christian_Catholic\n",
      "101 religion_Christian_Mormon\n",
      "102 religion_Christian_Other\n",
      "103 religion_Christian_Protestant\n",
      "104 religion_Hindu\n",
      "105 religion_Jewish\n",
      "106 religion_Muslim\n",
      "107 religion_Other\n",
      "108 religion_Sikh\n",
      "109 urban_0\n",
      "110 urban_1\n",
      "111 urban_2\n",
      "112 urban_3\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(train_x.columns):\n",
    "    print(i, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_x[:, 21:31] = (train_x[:, 21:31] - 3.5) / 3.5\n",
    "# test_x[:, 21:31] = (test_x[:, 21:31] - 3.5) / 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[:, 42:52] = (train_x[:, 42:52] - 3.5) / 3.5\n",
    "train_x[:, 41] = (train_x[:, 41]) / 3\n",
    "\n",
    "test_x[:, 41] = (test_x[:, 41]) / 3\n",
    "test_x[:, 42:52] = (test_x[:, 42:52] - 3.5) / 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x).float()\n",
    "train_y = torch.from_numpy(train_y).float()\n",
    "\n",
    "real_train_x = train_x\n",
    "real_train_y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31870, 13660)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = [.7, .3]\n",
    "\n",
    "train_cnt = int(train_x.size(0) * ratios[0])\n",
    "valid_cnt = train_x.size(0) - train_cnt\n",
    "cnts = [train_cnt, valid_cnt]\n",
    "train_cnt, valid_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31870, 113]) torch.Size([31870])\n",
      "torch.Size([13660, 113]) torch.Size([13660])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(train_x.size(0))\n",
    "\n",
    "train_x = torch.index_select(train_x, dim=0, index=indices)\n",
    "train_y = torch.index_select(train_y, dim=0, index=indices)\n",
    "\n",
    "train_x = train_x.split(cnts, dim=0)\n",
    "train_y = train_y.split(cnts, dim=0)\n",
    "\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "for x_i, y_i in zip(train_x, train_y):\n",
    "    print(x_i.size(), y_i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45530, 113])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "lowest_loss = np.inf\n",
    "best_model = None\n",
    "lowest_epoch = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train loss=2.1696e+02  valid_loss=5.9867e-01  lowest_loss=4.8739e-01\n",
      "Epoch 10: train loss=2.1273e+02  valid_loss=5.8520e-01  lowest_loss=4.8739e-01\n",
      "Epoch 15: train loss=2.0831e+02  valid_loss=5.7071e-01  lowest_loss=4.8739e-01\n",
      "Epoch 20: train loss=2.0494e+02  valid_loss=5.5755e-01  lowest_loss=4.8739e-01\n",
      "Epoch 25: train loss=2.0396e+02  valid_loss=5.5549e-01  lowest_loss=4.8739e-01\n",
      "Epoch 30: train loss=2.0669e+02  valid_loss=5.5910e-01  lowest_loss=4.8739e-01\n",
      "Epoch 35: train loss=2.0210e+02  valid_loss=5.4537e-01  lowest_loss=4.8739e-01\n",
      "Epoch 40: train loss=1.9679e+02  valid_loss=5.2010e-01  lowest_loss=4.8739e-01\n",
      "Epoch 45: train loss=1.9219e+02  valid_loss=5.0445e-01  lowest_loss=4.8739e-01\n",
      "Epoch 50: train loss=1.9108e+02  valid_loss=5.0025e-01  lowest_loss=4.8739e-01\n",
      "Epoch 55: train loss=1.9831e+02  valid_loss=5.3350e-01  lowest_loss=4.8739e-01\n",
      "Epoch 60: train loss=1.9476e+02  valid_loss=5.0717e-01  lowest_loss=4.8739e-01\n",
      "Epoch 65: train loss=1.8819e+02  valid_loss=4.9193e-01  lowest_loss=4.8470e-01\n",
      "Epoch 70: train loss=1.8354e+02  valid_loss=4.6365e-01  lowest_loss=4.6316e-01\n",
      "Epoch 75: train loss=1.8038e+02  valid_loss=4.5611e-01  lowest_loss=4.5683e-01\n",
      "Epoch 80: train loss=1.9257e+02  valid_loss=4.9665e-01  lowest_loss=4.5611e-01\n",
      "Epoch 85: train loss=1.8769e+02  valid_loss=4.7571e-01  lowest_loss=4.5611e-01\n",
      "Epoch 90: train loss=1.8284e+02  valid_loss=4.4999e-01  lowest_loss=4.5287e-01\n",
      "Epoch 95: train loss=1.7725e+02  valid_loss=4.3094e-01  lowest_loss=4.3375e-01\n",
      "Epoch 100: train loss=1.7394e+02  valid_loss=4.2532e-01  lowest_loss=4.2624e-01\n",
      "The best validation loss from epoch 100: 4.2532e-01\n",
      "Epoch 5: train loss=2.1682e+02  valid_loss=5.9953e-01  lowest_loss=4.2532e-01\n",
      "Epoch 10: train loss=2.1291e+02  valid_loss=5.8588e-01  lowest_loss=4.2532e-01\n",
      "Epoch 15: train loss=2.0900e+02  valid_loss=5.7298e-01  lowest_loss=4.2532e-01\n",
      "Epoch 20: train loss=2.0543e+02  valid_loss=5.5982e-01  lowest_loss=4.2532e-01\n",
      "Epoch 25: train loss=2.0380e+02  valid_loss=5.5564e-01  lowest_loss=4.2532e-01\n",
      "Epoch 30: train loss=2.0655e+02  valid_loss=5.5881e-01  lowest_loss=4.2532e-01\n",
      "Epoch 35: train loss=2.0280e+02  valid_loss=5.4345e-01  lowest_loss=4.2532e-01\n",
      "Epoch 40: train loss=1.9801e+02  valid_loss=5.2383e-01  lowest_loss=4.2532e-01\n",
      "Epoch 45: train loss=1.9367e+02  valid_loss=5.0938e-01  lowest_loss=4.2532e-01\n",
      "Epoch 50: train loss=1.9196e+02  valid_loss=5.0393e-01  lowest_loss=4.2532e-01\n",
      "Epoch 55: train loss=1.9905e+02  valid_loss=5.2930e-01  lowest_loss=4.2532e-01\n",
      "Epoch 60: train loss=1.9566e+02  valid_loss=5.1293e-01  lowest_loss=4.2532e-01\n",
      "Epoch 65: train loss=1.9081e+02  valid_loss=4.8980e-01  lowest_loss=4.2532e-01\n",
      "Epoch 70: train loss=1.8529e+02  valid_loss=4.7108e-01  lowest_loss=4.2532e-01\n",
      "Epoch 75: train loss=1.8379e+02  valid_loss=4.6586e-01  lowest_loss=4.2532e-01\n",
      "Epoch 80: train loss=1.9356e+02  valid_loss=4.9783e-01  lowest_loss=4.2532e-01\n",
      "Epoch 85: train loss=1.8983e+02  valid_loss=4.9533e-01  lowest_loss=4.2532e-01\n",
      "Epoch 90: train loss=1.8545e+02  valid_loss=4.6543e-01  lowest_loss=4.2532e-01\n",
      "Epoch 95: train loss=1.7926e+02  valid_loss=4.4368e-01  lowest_loss=4.2532e-01\n",
      "Epoch 100: train loss=1.7725e+02  valid_loss=4.3717e-01  lowest_loss=4.2532e-01\n",
      "The best validation loss from epoch 100: 4.2532e-01\n",
      "Epoch 5: train loss=2.1718e+02  valid_loss=6.0076e-01  lowest_loss=4.2532e-01\n",
      "Epoch 10: train loss=2.1361e+02  valid_loss=5.8847e-01  lowest_loss=4.2532e-01\n",
      "Epoch 15: train loss=2.0958e+02  valid_loss=5.7561e-01  lowest_loss=4.2532e-01\n",
      "Epoch 20: train loss=2.0545e+02  valid_loss=5.6564e-01  lowest_loss=4.2532e-01\n",
      "Epoch 25: train loss=2.0403e+02  valid_loss=5.5988e-01  lowest_loss=4.2532e-01\n",
      "Epoch 30: train loss=2.0786e+02  valid_loss=5.6192e-01  lowest_loss=4.2532e-01\n",
      "Epoch 35: train loss=2.0371e+02  valid_loss=5.5449e-01  lowest_loss=4.2532e-01\n",
      "Epoch 40: train loss=1.9789e+02  valid_loss=5.3288e-01  lowest_loss=4.2532e-01\n",
      "Epoch 45: train loss=1.9372e+02  valid_loss=5.1469e-01  lowest_loss=4.2532e-01\n",
      "Epoch 50: train loss=1.9272e+02  valid_loss=5.1053e-01  lowest_loss=4.2532e-01\n",
      "Epoch 55: train loss=1.9992e+02  valid_loss=5.2868e-01  lowest_loss=4.2532e-01\n",
      "Epoch 60: train loss=1.9572e+02  valid_loss=5.1543e-01  lowest_loss=4.2532e-01\n",
      "Epoch 65: train loss=1.9006e+02  valid_loss=4.8837e-01  lowest_loss=4.2532e-01\n",
      "Epoch 70: train loss=1.8414e+02  valid_loss=4.7046e-01  lowest_loss=4.2532e-01\n",
      "Epoch 75: train loss=1.8254e+02  valid_loss=4.6652e-01  lowest_loss=4.2532e-01\n",
      "Epoch 80: train loss=1.9341e+02  valid_loss=5.0266e-01  lowest_loss=4.2532e-01\n",
      "Epoch 85: train loss=1.8978e+02  valid_loss=4.9087e-01  lowest_loss=4.2532e-01\n",
      "Epoch 90: train loss=1.8262e+02  valid_loss=4.5915e-01  lowest_loss=4.2532e-01\n",
      "Epoch 95: train loss=1.7701e+02  valid_loss=4.4181e-01  lowest_loss=4.2532e-01\n",
      "Epoch 100: train loss=1.7456e+02  valid_loss=4.3280e-01  lowest_loss=4.2532e-01\n",
      "The best validation loss from epoch 100: 4.2532e-01\n",
      "Epoch 5: train loss=2.1741e+02  valid_loss=5.9996e-01  lowest_loss=4.2532e-01\n",
      "Epoch 10: train loss=2.1394e+02  valid_loss=5.8891e-01  lowest_loss=4.2532e-01\n",
      "Epoch 15: train loss=2.0956e+02  valid_loss=5.7642e-01  lowest_loss=4.2532e-01\n",
      "Epoch 20: train loss=2.0637e+02  valid_loss=5.6385e-01  lowest_loss=4.2532e-01\n",
      "Epoch 25: train loss=2.0484e+02  valid_loss=5.6111e-01  lowest_loss=4.2532e-01\n",
      "Epoch 30: train loss=2.0795e+02  valid_loss=5.6329e-01  lowest_loss=4.2532e-01\n",
      "Epoch 35: train loss=2.0368e+02  valid_loss=5.4803e-01  lowest_loss=4.2532e-01\n",
      "Epoch 40: train loss=1.9864e+02  valid_loss=5.2571e-01  lowest_loss=4.2532e-01\n",
      "Epoch 45: train loss=1.9411e+02  valid_loss=5.1252e-01  lowest_loss=4.2532e-01\n",
      "Epoch 50: train loss=1.9230e+02  valid_loss=5.0645e-01  lowest_loss=4.2532e-01\n",
      "Epoch 55: train loss=1.9946e+02  valid_loss=5.2412e-01  lowest_loss=4.2532e-01\n",
      "Epoch 60: train loss=1.9488e+02  valid_loss=5.0867e-01  lowest_loss=4.2532e-01\n",
      "Epoch 65: train loss=1.8903e+02  valid_loss=4.8373e-01  lowest_loss=4.2532e-01\n",
      "Epoch 70: train loss=1.8411e+02  valid_loss=4.6591e-01  lowest_loss=4.2532e-01\n",
      "Epoch 75: train loss=1.8115e+02  valid_loss=4.5733e-01  lowest_loss=4.2532e-01\n",
      "Epoch 80: train loss=1.9265e+02  valid_loss=5.0188e-01  lowest_loss=4.2532e-01\n",
      "Epoch 85: train loss=1.8849e+02  valid_loss=4.7992e-01  lowest_loss=4.2532e-01\n",
      "Epoch 90: train loss=1.8261e+02  valid_loss=4.5465e-01  lowest_loss=4.2532e-01\n",
      "Epoch 95: train loss=1.7721e+02  valid_loss=4.3443e-01  lowest_loss=4.2532e-01\n",
      "Epoch 100: train loss=1.7488e+02  valid_loss=4.2816e-01  lowest_loss=4.2532e-01\n",
      "The best validation loss from epoch 100: 4.2532e-01\n",
      "Epoch 5: train loss=2.1684e+02  valid_loss=5.9966e-01  lowest_loss=4.2532e-01\n",
      "Epoch 10: train loss=2.1329e+02  valid_loss=5.8894e-01  lowest_loss=4.2532e-01\n",
      "Epoch 15: train loss=2.0902e+02  valid_loss=5.7068e-01  lowest_loss=4.2532e-01\n",
      "Epoch 20: train loss=2.0527e+02  valid_loss=5.5947e-01  lowest_loss=4.2532e-01\n",
      "Epoch 25: train loss=2.0444e+02  valid_loss=5.5689e-01  lowest_loss=4.2532e-01\n",
      "Epoch 30: train loss=2.0763e+02  valid_loss=5.6298e-01  lowest_loss=4.2532e-01\n",
      "Epoch 35: train loss=2.0357e+02  valid_loss=5.4539e-01  lowest_loss=4.2532e-01\n",
      "Epoch 40: train loss=1.9761e+02  valid_loss=5.2402e-01  lowest_loss=4.2532e-01\n",
      "Epoch 45: train loss=1.9372e+02  valid_loss=5.0917e-01  lowest_loss=4.2532e-01\n",
      "Epoch 50: train loss=1.9134e+02  valid_loss=5.0299e-01  lowest_loss=4.2532e-01\n",
      "Epoch 55: train loss=1.9876e+02  valid_loss=5.2216e-01  lowest_loss=4.2532e-01\n",
      "Epoch 60: train loss=1.9429e+02  valid_loss=5.1068e-01  lowest_loss=4.2532e-01\n",
      "Epoch 65: train loss=1.8903e+02  valid_loss=4.8635e-01  lowest_loss=4.2532e-01\n",
      "Epoch 70: train loss=1.8404e+02  valid_loss=4.6805e-01  lowest_loss=4.2532e-01\n",
      "Epoch 75: train loss=1.8202e+02  valid_loss=4.6069e-01  lowest_loss=4.2532e-01\n",
      "Epoch 80: train loss=1.9226e+02  valid_loss=4.9413e-01  lowest_loss=4.2532e-01\n",
      "Epoch 85: train loss=1.8863e+02  valid_loss=4.8889e-01  lowest_loss=4.2532e-01\n",
      "Epoch 90: train loss=1.8212e+02  valid_loss=4.5642e-01  lowest_loss=4.2532e-01\n",
      "Epoch 95: train loss=1.7818e+02  valid_loss=4.4006e-01  lowest_loss=4.2532e-01\n",
      "Epoch 100: train loss=1.7478e+02  valid_loss=4.3023e-01  lowest_loss=4.2532e-01\n",
      "The best validation loss from epoch 100: 4.2532e-01\n",
      "Epoch 5: train loss=2.1717e+02  valid_loss=5.9889e-01  lowest_loss=4.2532e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train loss=2.1339e+02  valid_loss=5.8683e-01  lowest_loss=4.2532e-01\n",
      "Epoch 15: train loss=2.0959e+02  valid_loss=5.7372e-01  lowest_loss=4.2532e-01\n",
      "Epoch 20: train loss=2.0561e+02  valid_loss=5.6133e-01  lowest_loss=4.2532e-01\n",
      "Epoch 25: train loss=2.0380e+02  valid_loss=5.5873e-01  lowest_loss=4.2532e-01\n",
      "Epoch 30: train loss=2.0732e+02  valid_loss=5.6459e-01  lowest_loss=4.2532e-01\n",
      "Epoch 35: train loss=2.0349e+02  valid_loss=5.4474e-01  lowest_loss=4.2532e-01\n",
      "Epoch 40: train loss=1.9761e+02  valid_loss=5.2553e-01  lowest_loss=4.2532e-01\n",
      "Epoch 45: train loss=1.9301e+02  valid_loss=5.0491e-01  lowest_loss=4.2532e-01\n",
      "Epoch 50: train loss=1.9094e+02  valid_loss=5.0075e-01  lowest_loss=4.2532e-01\n",
      "Epoch 55: train loss=1.9810e+02  valid_loss=5.2159e-01  lowest_loss=4.2532e-01\n",
      "Epoch 60: train loss=1.9513e+02  valid_loss=5.0801e-01  lowest_loss=4.2532e-01\n",
      "Epoch 65: train loss=1.8895e+02  valid_loss=4.8479e-01  lowest_loss=4.2532e-01\n",
      "Epoch 70: train loss=1.8362e+02  valid_loss=4.6454e-01  lowest_loss=4.2532e-01\n",
      "Epoch 75: train loss=1.8108e+02  valid_loss=4.5478e-01  lowest_loss=4.2532e-01\n",
      "Epoch 80: train loss=1.9234e+02  valid_loss=4.9943e-01  lowest_loss=4.2532e-01\n",
      "Epoch 85: train loss=1.8881e+02  valid_loss=4.8024e-01  lowest_loss=4.2532e-01\n",
      "Epoch 90: train loss=1.8302e+02  valid_loss=4.5887e-01  lowest_loss=4.2532e-01\n",
      "Epoch 95: train loss=1.7691e+02  valid_loss=4.2760e-01  lowest_loss=4.2532e-01\n",
      "Epoch 100: train loss=1.7424e+02  valid_loss=4.2114e-01  lowest_loss=4.2253e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1774e+02  valid_loss=5.9835e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1347e+02  valid_loss=5.9114e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.0976e+02  valid_loss=5.7474e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0587e+02  valid_loss=5.6336e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0409e+02  valid_loss=5.6001e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0751e+02  valid_loss=5.5968e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0261e+02  valid_loss=5.4742e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9765e+02  valid_loss=5.2589e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9263e+02  valid_loss=5.0986e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9143e+02  valid_loss=5.0405e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9885e+02  valid_loss=5.3154e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9470e+02  valid_loss=5.0929e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8836e+02  valid_loss=4.8541e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8358e+02  valid_loss=4.6483e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8148e+02  valid_loss=4.5885e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9191e+02  valid_loss=4.9884e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8888e+02  valid_loss=4.8585e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8294e+02  valid_loss=4.6145e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7615e+02  valid_loss=4.3257e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7512e+02  valid_loss=4.2875e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1718e+02  valid_loss=6.0161e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1320e+02  valid_loss=5.8842e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.0938e+02  valid_loss=5.7221e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0566e+02  valid_loss=5.6194e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0441e+02  valid_loss=5.5915e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0691e+02  valid_loss=5.6452e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0300e+02  valid_loss=5.4879e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9774e+02  valid_loss=5.2856e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9327e+02  valid_loss=5.1180e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9134e+02  valid_loss=5.0519e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9962e+02  valid_loss=5.2679e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9561e+02  valid_loss=5.1238e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8953e+02  valid_loss=4.9168e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8390e+02  valid_loss=4.7101e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8138e+02  valid_loss=4.6561e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9313e+02  valid_loss=5.0253e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8845e+02  valid_loss=4.8193e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8350e+02  valid_loss=4.6237e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7852e+02  valid_loss=4.4125e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7499e+02  valid_loss=4.3579e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1698e+02  valid_loss=5.9871e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1293e+02  valid_loss=5.8491e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.0925e+02  valid_loss=5.7453e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0615e+02  valid_loss=5.6309e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0410e+02  valid_loss=5.5908e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0776e+02  valid_loss=5.6410e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0388e+02  valid_loss=5.5060e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9905e+02  valid_loss=5.3023e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9431e+02  valid_loss=5.1290e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9221e+02  valid_loss=5.0704e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9931e+02  valid_loss=5.3137e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9599e+02  valid_loss=5.1274e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8975e+02  valid_loss=4.9184e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8485e+02  valid_loss=4.7450e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8226e+02  valid_loss=4.6590e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9279e+02  valid_loss=5.1594e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8982e+02  valid_loss=4.9228e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8406e+02  valid_loss=4.6675e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7876e+02  valid_loss=4.4302e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7599e+02  valid_loss=4.3620e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1706e+02  valid_loss=6.0152e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1353e+02  valid_loss=5.8921e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.1004e+02  valid_loss=5.7569e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0608e+02  valid_loss=5.6618e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0566e+02  valid_loss=5.6202e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0779e+02  valid_loss=5.7153e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0371e+02  valid_loss=5.4862e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9801e+02  valid_loss=5.2509e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9391e+02  valid_loss=5.1428e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9193e+02  valid_loss=5.0792e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9947e+02  valid_loss=5.3307e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9494e+02  valid_loss=5.1364e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8967e+02  valid_loss=4.8914e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8381e+02  valid_loss=4.6883e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8195e+02  valid_loss=4.6283e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9349e+02  valid_loss=5.0198e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8929e+02  valid_loss=4.8093e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8320e+02  valid_loss=4.6047e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7745e+02  valid_loss=4.3717e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7402e+02  valid_loss=4.2855e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1737e+02  valid_loss=5.9898e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1347e+02  valid_loss=5.9114e-01  lowest_loss=4.2114e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train loss=2.0927e+02  valid_loss=5.7444e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0566e+02  valid_loss=5.6249e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0452e+02  valid_loss=5.5913e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0706e+02  valid_loss=5.6291e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0284e+02  valid_loss=5.4545e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9718e+02  valid_loss=5.2358e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9295e+02  valid_loss=5.0736e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9175e+02  valid_loss=5.0253e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9869e+02  valid_loss=5.3056e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9434e+02  valid_loss=5.1414e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8890e+02  valid_loss=4.8392e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8434e+02  valid_loss=4.6762e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8205e+02  valid_loss=4.5929e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9232e+02  valid_loss=5.1176e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8920e+02  valid_loss=4.8050e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8402e+02  valid_loss=4.6210e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7777e+02  valid_loss=4.3618e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7489e+02  valid_loss=4.2934e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1685e+02  valid_loss=6.0858e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1333e+02  valid_loss=5.8815e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.0992e+02  valid_loss=5.7615e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0707e+02  valid_loss=5.6468e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0527e+02  valid_loss=5.6081e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0825e+02  valid_loss=5.6931e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0376e+02  valid_loss=5.4388e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9901e+02  valid_loss=5.2921e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9426e+02  valid_loss=5.0899e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9137e+02  valid_loss=5.0462e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9885e+02  valid_loss=5.2285e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9540e+02  valid_loss=5.1245e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8910e+02  valid_loss=4.8136e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8321e+02  valid_loss=4.6558e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8214e+02  valid_loss=4.5892e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9249e+02  valid_loss=4.9192e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8888e+02  valid_loss=4.8487e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8219e+02  valid_loss=4.4921e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7575e+02  valid_loss=4.3369e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7452e+02  valid_loss=4.2350e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1739e+02  valid_loss=5.9771e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1356e+02  valid_loss=5.8958e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.0931e+02  valid_loss=5.7455e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0614e+02  valid_loss=5.6294e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0431e+02  valid_loss=5.5974e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0729e+02  valid_loss=5.6242e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0420e+02  valid_loss=5.5110e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9762e+02  valid_loss=5.2725e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9363e+02  valid_loss=5.0988e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9176e+02  valid_loss=5.0557e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9853e+02  valid_loss=5.2201e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9438e+02  valid_loss=5.1762e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8949e+02  valid_loss=4.8721e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8388e+02  valid_loss=4.6511e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8126e+02  valid_loss=4.6069e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9248e+02  valid_loss=5.0184e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8934e+02  valid_loss=4.8278e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8247e+02  valid_loss=4.6045e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7678e+02  valid_loss=4.3546e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7448e+02  valid_loss=4.2755e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1697e+02  valid_loss=5.9929e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1340e+02  valid_loss=5.8661e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.1000e+02  valid_loss=5.7450e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0614e+02  valid_loss=5.6240e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0516e+02  valid_loss=5.5995e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0777e+02  valid_loss=5.7243e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0377e+02  valid_loss=5.5277e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9858e+02  valid_loss=5.2851e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9370e+02  valid_loss=5.1094e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9181e+02  valid_loss=5.0597e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9920e+02  valid_loss=5.2474e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9509e+02  valid_loss=5.0718e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8954e+02  valid_loss=4.8418e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8431e+02  valid_loss=4.6628e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8196e+02  valid_loss=4.5979e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9339e+02  valid_loss=4.9576e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8902e+02  valid_loss=4.8448e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8347e+02  valid_loss=4.5537e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7710e+02  valid_loss=4.3668e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7375e+02  valid_loss=4.2954e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n",
      "Epoch 5: train loss=2.1756e+02  valid_loss=6.0125e-01  lowest_loss=4.2114e-01\n",
      "Epoch 10: train loss=2.1308e+02  valid_loss=5.8747e-01  lowest_loss=4.2114e-01\n",
      "Epoch 15: train loss=2.0922e+02  valid_loss=5.7284e-01  lowest_loss=4.2114e-01\n",
      "Epoch 20: train loss=2.0530e+02  valid_loss=5.6322e-01  lowest_loss=4.2114e-01\n",
      "Epoch 25: train loss=2.0394e+02  valid_loss=5.6038e-01  lowest_loss=4.2114e-01\n",
      "Epoch 30: train loss=2.0737e+02  valid_loss=5.6327e-01  lowest_loss=4.2114e-01\n",
      "Epoch 35: train loss=2.0318e+02  valid_loss=5.4775e-01  lowest_loss=4.2114e-01\n",
      "Epoch 40: train loss=1.9836e+02  valid_loss=5.3047e-01  lowest_loss=4.2114e-01\n",
      "Epoch 45: train loss=1.9347e+02  valid_loss=5.1372e-01  lowest_loss=4.2114e-01\n",
      "Epoch 50: train loss=1.9173e+02  valid_loss=5.0816e-01  lowest_loss=4.2114e-01\n",
      "Epoch 55: train loss=1.9895e+02  valid_loss=5.3157e-01  lowest_loss=4.2114e-01\n",
      "Epoch 60: train loss=1.9563e+02  valid_loss=5.1357e-01  lowest_loss=4.2114e-01\n",
      "Epoch 65: train loss=1.8977e+02  valid_loss=4.8976e-01  lowest_loss=4.2114e-01\n",
      "Epoch 70: train loss=1.8492e+02  valid_loss=4.6985e-01  lowest_loss=4.2114e-01\n",
      "Epoch 75: train loss=1.8086e+02  valid_loss=4.6333e-01  lowest_loss=4.2114e-01\n",
      "Epoch 80: train loss=1.9398e+02  valid_loss=5.0614e-01  lowest_loss=4.2114e-01\n",
      "Epoch 85: train loss=1.8867e+02  valid_loss=4.8174e-01  lowest_loss=4.2114e-01\n",
      "Epoch 90: train loss=1.8274e+02  valid_loss=4.6460e-01  lowest_loss=4.2114e-01\n",
      "Epoch 95: train loss=1.7654e+02  valid_loss=4.3556e-01  lowest_loss=4.2114e-01\n",
      "Epoch 100: train loss=1.7473e+02  valid_loss=4.2949e-01  lowest_loss=4.2114e-01\n",
      "The best validation loss from epoch 100: 4.2114e-01\n"
     ]
    }
   ],
   "source": [
    "train_len, test_len = len(train_x), len(test_x)\n",
    "early_stop = 30\n",
    "print_interval = 5\n",
    "N_MODEL = 15\n",
    "N_EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False\n",
    "}\n",
    "prediction_valid = np.zeros((13660, 1), dtype=np.float32)\n",
    "prediction_test = np.zeros((11383, 1), dtype=np.float32)\n",
    "\n",
    "for no in range(N_MODEL):\n",
    "\n",
    "    real_train_loader = DataLoader(TensorDataset(real_train_x, real_train_y),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(train_x[0], train_y[0]),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "    valid_loader = DataLoader(TensorDataset(train_x[1], train_y[1]),\n",
    "                                  shuffle=False, drop_last=True, **LOADER_PARAM)\n",
    "    \n",
    "    test_loader = DataLoader(TensorDataset(test_x, torch.zeros((test_len,), dtype=torch.float32, device=DEVICE)),\n",
    "                                 shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "    model = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(113, 120, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "        \n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(120, 90, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "        \n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(90, 60, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "        \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(60, 30, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "            \n",
    "            nn.Linear(30, 1)\n",
    "    ).to(DEVICE)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=4e-2)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=N_EPOCH // 4, eta_min=1.2e-5)\n",
    "\n",
    "    for epoch in range(N_EPOCH):\n",
    "#     for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(no + 1, N_MODEL)):\n",
    "        \n",
    "        train_loss, valid_loss = 0, 0\n",
    "        y_hat = []\n",
    "    \n",
    "        model.train()\n",
    "        for idx, (xx, yy) in enumerate(real_train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "            pred = model(xx).squeeze()\n",
    "            loss = criterion(pred, yy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch + idx / len(real_train_loader))\n",
    "            \n",
    "            train_loss += float(loss)\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0\n",
    "            for idx, (xx, yy) in enumerate(valid_loader):\n",
    "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                pred = model(xx).squeeze()\n",
    "                loss = criterion(pred, yy)\n",
    "                \n",
    "                valid_loss += float(loss)\n",
    "                y_hat += [pred]\n",
    "                \n",
    "        valid_loss = valid_loss / len(valid_loader)\n",
    "#         valid_history += [valid_loss]\n",
    "        \n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            print('Epoch %d: train loss=%.4e  valid_loss=%.4e  lowest_loss=%.4e' % (\n",
    "                epoch + 1,\n",
    "                train_loss,\n",
    "                valid_loss,\n",
    "                lowest_loss,\n",
    "            ))\n",
    "        \n",
    "        if valid_loss <= lowest_loss:\n",
    "            lowest_loss = valid_loss\n",
    "            lowest_epoch = epoch\n",
    "\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            if early_stop > 0 and lowest_epoch + early_stop < epoch + 1:\n",
    "                print(\"There is no improvement during last %d epochs.\" % early_stop)\n",
    "                break\n",
    "                \n",
    "    print(\"The best validation loss from epoch %d: %.4e\" % (lowest_epoch + 1, lowest_loss))\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    #### validation ####\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (xx, _) in enumerate(valid_loader): ## valid_loader 교체\n",
    "#             xx = xx.to(DEVICE)\n",
    "#             pred = (torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "#             prediction_valid[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction_valid)), :] += pred[:, :] / N_MODEL\n",
    "#             ## prediction_test 교체\n",
    "            \n",
    "    \n",
    "    #### test ####\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (xx, _) in enumerate(test_loader): ## valid_loader 교체\n",
    "            xx = xx.to(DEVICE)\n",
    "            pred = (torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "            prediction_test[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction_test)), :] += pred[:, :] / N_MODEL\n",
    "    \n",
    "\n",
    "df = pd.read_csv('./data/sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction_test\n",
    "df.to_csv('./result/{}.csv'.format(datetime.now().strftime('%m%d-%H%M')), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(train_y[1], prediction_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = 2 - prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction_test\n",
    "df.to_csv('./result/{}.csv'.format(datetime.now().strftime('%m%d-%H%M')), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
